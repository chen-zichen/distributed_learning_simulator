2021-01-19 20:10:12,756 INFO {thd:140309832484672} [arg_parse.py => 72] : use dataset MNIST and model LeNet5
2021-01-19 20:10:25,873 INFO {thd:140307073500928} [trainer.py => 144] : training_set_size is 49995
2021-01-19 20:10:25,873 INFO {thd:140307073500928} [trainer.py => 148] : use device cuda:0
2021-01-19 20:10:25,873 INFO {thd:140309832484672} [simulator.py => 52] : begin training
2021-01-19 20:10:26,801 INFO {thd:140307073500928} [trainer.py => 354] : begin training, hyper_parameter is epochs:1 batch_size:64 learning_rate:0.01 weight_decay:1 optimizer:<class 'torch.optim.sgd.SGD'>, optimizer is SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 2.0002000200020003e-05
) ,lr_scheduler is <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f9be98c7070>, model: QuantedModel, loss_fun: NLLLoss(), parameter number is 61706
2021-01-19 20:10:28,145 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 0, learning rate: [0.01], batch training loss: 2.2948474884033203
2021-01-19 20:10:29,984 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 78, learning rate: [0.01], batch training loss: 1.1989744901657104
2021-01-19 20:10:31,862 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 156, learning rate: [0.01], batch training loss: 0.1804264485836029
2021-01-19 20:10:33,647 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 234, learning rate: [0.01], batch training loss: 0.08565817028284073
2021-01-19 20:10:35,411 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 312, learning rate: [0.01], batch training loss: 0.1939718872308731
2021-01-19 20:10:37,148 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 390, learning rate: [0.01], batch training loss: 0.11698676645755768
2021-01-19 20:10:38,923 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 468, learning rate: [0.01], batch training loss: 0.1523115336894989
2021-01-19 20:10:40,749 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 546, learning rate: [0.01], batch training loss: 0.06381283700466156
2021-01-19 20:10:42,560 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 624, learning rate: [0.01], batch training loss: 0.0668642669916153
2021-01-19 20:10:44,334 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 702, learning rate: [0.01], batch training loss: 0.056401386857032776
2021-01-19 20:10:46,132 INFO {thd:140307073500928} [trainer.py => 371] : epoch: 1, batch: 780, learning rate: [0.01], batch training loss: 0.28743910789489746
2021-01-19 20:10:46,260 INFO {thd:140307073500928} [trainer.py => 395] : epoch: 1, training loss: 0.38866525971838195
2021-01-19 20:10:47,463 INFO {thd:140307073500928} [inference.py => 62] : use device cuda
2021-01-19 20:10:50,450 INFO {thd:140307073500928} [trainer.py => 422] : epoch: 1, learning_rate: [0.01], validation loss: 0.08688902854919434, accuracy = 0.9750124937531235
2021-01-19 20:10:51,529 INFO {thd:140307073500928} [inference.py => 62] : use device cuda
2021-01-19 20:10:54,532 INFO {thd:140307073500928} [trainer.py => 471] : epoch: 1, learning_rate: [0.01], test loss: 0.08245133608579636, accuracy = 0.9734
2021-01-19 20:10:54,637 DEBUG {thd:140307073500928} [trainer.py => 290] : call ReduceLROnPlateau for total loss 0.4755542882675763
2021-01-19 20:10:55,751 INFO {thd:140307073500928} [inference.py => 62] : use device cpu
2021-01-19 20:10:55,759 ERROR {thd:140307073500928} [executor_pool.py => 37] : catch exception:'Conv2d' object has no attribute '_forward_pre_hooks'
2021-01-19 20:10:55,760 ERROR {thd:140307073500928} [executor_pool.py => 38] : traceback:Traceback (most recent call last):
  File "/home/cyy/.local/lib/python3.9/site-packages/cyy_naive_lib-0.1-py3.9.egg/cyy_naive_lib/data_structure/executor_pool.py", line 35, in process
    fn(*args, **kwargs)
  File "/home/cyy/distributed_learning_simulator/fed_quant_worker.py", line 51, in train
    res = inferencer.inference(device=get_cpu_device())
  File "/home/cyy/.local/lib/python3.9/site-packages/cyy_naive_pytorch_lib-0.1-py3.9.egg/cyy_naive_pytorch_lib/inference.py", line 127, in inference
    loss = super().inference(**kwargs)
  File "/home/cyy/.local/lib/python3.9/site-packages/cyy_naive_pytorch_lib-0.1-py3.9.egg/cyy_naive_pytorch_lib/inference.py", line 73, in inference
    result = self.__model_with_loss(inputs, targets, phase=self.__phase)
  File "/home/cyy/.local/lib/python3.9/site-packages/cyy_naive_pytorch_lib-0.1-py3.9.egg/cyy_naive_pytorch_lib/model_loss.py", line 73, in __call__
    output = self.__model(inputs)
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 940, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cyy/distributed_learning_simulator/quant_model.py", line 45, in forward
    x = self.submodule(x)
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 940, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cyy/.local/lib/python3.9/site-packages/cyy_naive_pytorch_lib-0.1-py3.9.egg/cyy_naive_pytorch_lib/models/lenet.py", line 54, in forward
    output = self.convnet(x)
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 940, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 924, in _call_impl
    _global_forward_pre_hooks.values(), self._forward_pre_hooks.values()
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 998, in __getattr__
    raise AttributeError(
AttributeError: 'Conv2d' object has no attribute '_forward_pre_hooks'

2021-01-19 20:10:55,760 INFO {thd:140309832484672} [simulator.py => 54] : end training
