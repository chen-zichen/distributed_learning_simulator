2021-01-19 20:12:52,736 INFO {thd:140349948438336} [arg_parse.py => 72] : use dataset MNIST and model LeNet5
2021-01-19 20:13:06,143 INFO {thd:140347015636736} [trainer.py => 144] : training_set_size is 49995
2021-01-19 20:13:06,143 INFO {thd:140347015636736} [trainer.py => 148] : use device cuda:0
2021-01-19 20:13:06,143 INFO {thd:140349948438336} [simulator.py => 52] : begin training
2021-01-19 20:13:07,094 INFO {thd:140347015636736} [trainer.py => 354] : begin training, hyper_parameter is epochs:1 batch_size:64 learning_rate:0.01 weight_decay:1 optimizer:<class 'torch.optim.sgd.SGD'>, optimizer is SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 2.0002000200020003e-05
) ,lr_scheduler is <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fa53ea54070>, model: QuantedModel, loss_fun: NLLLoss(), parameter number is 61706
2021-01-19 20:13:08,389 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 0, learning rate: [0.01], batch training loss: 2.3254363536834717
2021-01-19 20:13:10,229 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 78, learning rate: [0.01], batch training loss: 1.1575124263763428
2021-01-19 20:13:12,000 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 156, learning rate: [0.01], batch training loss: 0.2477150559425354
2021-01-19 20:13:13,745 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 234, learning rate: [0.01], batch training loss: 0.09592954069375992
2021-01-19 20:13:15,493 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 312, learning rate: [0.01], batch training loss: 0.05625489354133606
2021-01-19 20:13:17,301 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 390, learning rate: [0.01], batch training loss: 0.03339257836341858
2021-01-19 20:13:19,045 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 468, learning rate: [0.01], batch training loss: 0.09456031769514084
2021-01-19 20:13:20,781 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 546, learning rate: [0.01], batch training loss: 0.24747802317142487
2021-01-19 20:13:22,509 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 624, learning rate: [0.01], batch training loss: 0.036427464336156845
2021-01-19 20:13:24,359 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 702, learning rate: [0.01], batch training loss: 0.12369706481695175
2021-01-19 20:13:26,057 INFO {thd:140347015636736} [trainer.py => 371] : epoch: 1, batch: 780, learning rate: [0.01], batch training loss: 0.05829555541276932
2021-01-19 20:13:26,180 INFO {thd:140347015636736} [trainer.py => 395] : epoch: 1, training loss: 0.38440988624129785
2021-01-19 20:13:27,389 INFO {thd:140347015636736} [inference.py => 62] : use device cuda
2021-01-19 20:13:30,435 INFO {thd:140347015636736} [trainer.py => 422] : epoch: 1, learning_rate: [0.01], validation loss: 0.10389206558465958, accuracy = 0.9689155422288855
2021-01-19 20:13:31,526 INFO {thd:140347015636736} [inference.py => 62] : use device cuda
2021-01-19 20:13:34,592 INFO {thd:140347015636736} [trainer.py => 471] : epoch: 1, learning_rate: [0.01], test loss: 0.10226336121559143, accuracy = 0.9662
2021-01-19 20:13:34,698 DEBUG {thd:140347015636736} [trainer.py => 290] : call ReduceLROnPlateau for total loss 0.4883019518259574
2021-01-19 20:13:35,807 INFO {thd:140347015636736} [inference.py => 62] : use device cuda
2021-01-19 20:13:35,814 ERROR {thd:140347015636736} [executor_pool.py => 37] : catch exception:'Conv2d' object has no attribute '_forward_pre_hooks'
2021-01-19 20:13:35,815 ERROR {thd:140347015636736} [executor_pool.py => 38] : traceback:Traceback (most recent call last):
  File "/home/cyy/.local/lib/python3.9/site-packages/cyy_naive_lib-0.1-py3.9.egg/cyy_naive_lib/data_structure/executor_pool.py", line 35, in process
    fn(*args, **kwargs)
  File "/home/cyy/distributed_learning_simulator/fed_quant_worker.py", line 52, in train
    res = inferencer.inference()
  File "/home/cyy/.local/lib/python3.9/site-packages/cyy_naive_pytorch_lib-0.1-py3.9.egg/cyy_naive_pytorch_lib/inference.py", line 127, in inference
    loss = super().inference(**kwargs)
  File "/home/cyy/.local/lib/python3.9/site-packages/cyy_naive_pytorch_lib-0.1-py3.9.egg/cyy_naive_pytorch_lib/inference.py", line 73, in inference
    result = self.__model_with_loss(inputs, targets, phase=self.__phase)
  File "/home/cyy/.local/lib/python3.9/site-packages/cyy_naive_pytorch_lib-0.1-py3.9.egg/cyy_naive_pytorch_lib/model_loss.py", line 73, in __call__
    output = self.__model(inputs)
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 940, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cyy/distributed_learning_simulator/quant_model.py", line 45, in forward
    x = self.submodule(x)
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 940, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cyy/.local/lib/python3.9/site-packages/cyy_naive_pytorch_lib-0.1-py3.9.egg/cyy_naive_pytorch_lib/models/lenet.py", line 54, in forward
    output = self.convnet(x)
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 940, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 924, in _call_impl
    _global_forward_pre_hooks.values(), self._forward_pre_hooks.values()
  File "/home/cyy/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 998, in __getattr__
    raise AttributeError(
AttributeError: 'Conv2d' object has no attribute '_forward_pre_hooks'

