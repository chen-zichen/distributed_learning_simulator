2021-04-06 13:16:14,027 INFO {thd:139717940455232} [arg_parse.py => 72] : use dataset MNIST and model LeNet5
2021-04-06 13:16:29,334 INFO {thd:139715447199296} [trainer.py => 144] : training_set_size is 49995
2021-04-06 13:16:29,334 INFO {thd:139715447199296} [trainer.py => 148] : use device cuda:0
2021-04-06 13:16:29,334 INFO {thd:139717940455232} [simulator.py => 52] : begin training
2021-04-06 13:16:31,136 INFO {thd:139715447199296} [trainer.py => 359] : begin training, hyper_parameter is epochs:1 batch_size:64 learning_rate:0.01 weight_decay:1 optimizer:<class 'torch.optim.sgd.SGD'>, optimizer is SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 2.0002000200020003e-05
) ,lr_scheduler is <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f12222c0450>, model: LeNet5, loss_fun: NLLLoss(), parameter number is 61706
2021-04-06 13:16:31,397 INFO {thd:139715447199296} [trainer.py => 375] : epoch: 1, batch: 0, learning rate: [0.01], batch training loss: 2.286534309387207
2021-04-06 13:16:33,411 INFO {thd:139715447199296} [trainer.py => 375] : epoch: 1, batch: 78, learning rate: [0.01], batch training loss: 0.542891800403595
2021-04-06 13:16:35,472 INFO {thd:139715447199296} [trainer.py => 375] : epoch: 1, batch: 156, learning rate: [0.01], batch training loss: 0.4083380401134491
2021-04-06 13:16:37,532 INFO {thd:139715447199296} [trainer.py => 375] : epoch: 1, batch: 234, learning rate: [0.01], batch training loss: 0.17884908616542816
2021-04-06 13:16:39,591 INFO {thd:139715447199296} [trainer.py => 375] : epoch: 1, batch: 312, learning rate: [0.01], batch training loss: 0.1376083791255951
2021-04-06 13:16:41,601 INFO {thd:139715447199296} [trainer.py => 375] : epoch: 1, batch: 390, learning rate: [0.01], batch training loss: 0.1868171989917755
2021-04-06 13:16:43,653 INFO {thd:139715447199296} [trainer.py => 375] : epoch: 1, batch: 468, learning rate: [0.01], batch training loss: 0.0659400150179863
2021-04-06 13:16:45,733 INFO {thd:139715447199296} [trainer.py => 375] : epoch: 1, batch: 546, learning rate: [0.01], batch training loss: 0.0459066778421402
2021-04-06 13:16:47,812 INFO {thd:139715447199296} [trainer.py => 375] : epoch: 1, batch: 624, learning rate: [0.01], batch training loss: 0.09401813894510269
